import os
from openai import OpenAI
from dotenv import load_dotenv
from typing import List, Dict

# åŠ è½½ .env æ–‡ä»¶ä¸­çš„ç¯å¢ƒå˜é‡
load_dotenv()

class HelloAgentsLLM:
  """
  "Hello Agents"å®šåˆ¶çš„LLMå®¢æˆ·ç«¯
  ç”¨äºè°ƒç”¨ä»»ä½•å…¼å®¹OpenAIæ¥å£çš„æœåŠ¡ï¼Œé»˜è®¤ä½¿ç”¨æµå¼å“åº”
  """
  def __init__(self, model:str=None, apiKey:str=None, baseUrl:str=None, timeout:int=None):
    """
    åˆå§‹åŒ–å®¢æˆ·ç«¯ï¼Œä¼˜å…ˆä½¿ç”¨ä¼ å…¥å‚æ•°ï¼Œå…¶æ¬¡ä»ç¯å¢ƒå˜é‡åŠ è½½
    """
    self.model = model or os.getenv("LLM_MODEL_ID")
    apiKey = apiKey or os.getenv("LLM_API_KEY")
    baseUrl = baseUrl or os.getenv("LLM_BASE_URL")
    timeout = timeout or int(os.getenv("LLM_TIMEOUT", 60))
    
    if not all([self.model, apiKey, baseUrl]):
      raise ValueError("æ¨¡å‹IDã€APIå¯†é’¥å’ŒæœåŠ¡åœ°å€å¿…é¡»è¢«æä¾›æˆ–åœ¨.envæ–‡ä»¶ä¸­å®šä¹‰ã€‚")
    self.client = OpenAI(api_key=apiKey, base_url=baseUrl, timeout=timeout)

  def think(self, messages:List[Dict[str:str]], temperature:float=0) -> str:
    """
    è°ƒç”¨å¤§è¯­è¨€æ¨¡å‹æ€è€ƒï¼Œè¿”å›å“åº”
    """
    print(f"ğŸ§  æ­£åœ¨è°ƒç”¨{self.model}æ¨¡å‹...")
    try:
      # è°ƒç”¨clientç”Ÿæˆå›åº”
      response = self.client.chat.completions.create(
        messages=messages,
        model=self.model,
        temperature=temperature,
        stream=True,
      )
      # å¤„ç†æµå¼å“åº” ä¸€è¡Œè¡Œåˆ·å‡º
      print("âœ” å¤§è¯­è¨€æ¨¡å‹å“åº”æˆåŠŸï¼š")
      collected_content = []
      for chunk in response:
        content = chunk.choices[0].delta.content or ""
        print(content, end="", flush=True)
        collected_content.append(content)
      print() # æµå¼è¾“å‡ºç»“æŸåæ¢è¡Œ
      return "".join(collected_content)

    except Exception as e:
      print(f"âŒ è°ƒç”¨LLM APIæ—¶å‘ç”Ÿé”™è¯¯ï¼š{e}")
      return None

# -----å®¢æˆ·ç«¯ä½¿ç”¨ç¤ºä¾‹-----
# if __name__=='__main__':
#   try:
#     llmClient = HelloAgentsLLM()
#     examplemsgs = [
#       {"role": "system", "content": "You are a helpful assistant that writes Python code."},
#       {"role": "user", "content": "å†™ä¸€ä¸ªå¿«é€Ÿæ’åºç®—æ³•"}
#     ]
#     print("----è°ƒç”¨LLM----")
#     responseText = llmClient.think(examplemsgs, temperature=0)
#     if responseText:
#       print("\n\n----å®Œæ•´æ¨¡å‹å“åº”----")
#       print(responseText)
#   except ValueError as e:
#     print(e)

